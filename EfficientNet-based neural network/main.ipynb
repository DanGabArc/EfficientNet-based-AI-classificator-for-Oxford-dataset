{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f53f04a",
   "metadata": {},
   "source": [
    "Libraries importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44d973e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f68f2b",
   "metadata": {},
   "source": [
    "Directories determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18d2353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = r'C:\\Users\\user\\Desktop\\Neuro\\data\\train'\n",
    "val_data_dir = r'C:\\Users\\user\\Desktop\\Neuro\\data\\valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f83dea3",
   "metadata": {},
   "source": [
    "Data - normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f62ca7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    tf.keras.applications.efficientnet.preprocess_input,\n",
    "    rotation_range=5,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.18,\n",
    "    zoom_range=0.18,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    channel_shift_range=6.5,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Only normalization to val section\n",
    "val_datagen = ImageDataGenerator(tf.keras.applications.efficientnet.preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52217b",
   "metadata": {},
   "source": [
    "Data - generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dd40a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6552 images belonging to 102 classes.\n",
      "Found 818 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=48,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size = 48,\n",
    "    class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0923f2f0",
   "metadata": {},
   "source": [
    "Let's determine base model and freeze it to prevent training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f8b6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfd522",
   "metadata": {},
   "source": [
    "Build new layers and unfreeze last 40 layers of EffecientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8bfa85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    layers.Dense(102, activation='softmax')\n",
    "])\n",
    "\n",
    "for layer in base_model.layers[-40:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f233d783",
   "metadata": {},
   "source": [
    "Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f58a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa071b2",
   "metadata": {},
   "source": [
    "Model - training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4d9ac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1263: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 829ms/step - accuracy: 0.1216 - loss: 8.3253 - val_accuracy: 0.4352 - val_loss: 5.8335\n",
      "Epoch 2/6\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 813ms/step - accuracy: 0.5959 - loss: 5.4535 - val_accuracy: 0.8350 - val_loss: 3.7313\n",
      "Epoch 3/6\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 810ms/step - accuracy: 0.8547 - loss: 3.7060 - val_accuracy: 0.9218 - val_loss: 2.9577\n",
      "Epoch 4/6\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 834ms/step - accuracy: 0.9294 - loss: 2.8630 - val_accuracy: 0.9389 - val_loss: 2.4182\n",
      "Epoch 5/6\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 814ms/step - accuracy: 0.9537 - loss: 2.3297 - val_accuracy: 0.9499 - val_loss: 2.0027\n",
      "Epoch 6/6\n",
      "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 813ms/step - accuracy: 0.9588 - loss: 1.9237 - val_accuracy: 0.9572 - val_loss: 1.6631\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=6,  # Больше эпох\n",
    "    validation_data=val_generator,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
